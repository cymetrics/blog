<!DOCTYPE html><html domain="tech-blog.cymetrics.io" ga-id="G-3VBVCXV9Z0" lang="zh-TW"><head><meta charset="utf-8"><meta content="width=device-width,initial-scale=1" name="viewport"><meta content="CYBER,Cymetrics,Security" name="keywords"><link href="/img/favicon/favicon-192x192.png?hash=42b087227d" rel="icon" type="image/png"><meta content="#5789d3" name="theme-color"><title>Practical Applications and Challenges of OpenAI Embeddings and Retrieval-Augmented Generation</title><meta content="Practical Applications and Challenges of OpenAI Embeddings and Retrieval-Augmented Generation" property="og:title"><meta content="Practical Applications and Challenges of OpenAI Embeddings and Retrieval-Augmented Generation" name="twitter:title"><meta content="summary_large_image" name="twitter:card"><meta content="Would you like to understand the pitfalls encountered in developing OpenAI?Would you like to understand how to unlock Embeddings and Retrieval-Augmented Generation to enable GPT models to generate meaningful content, even without the unique know-how of enterprises? Then hurry up and click in, and leave with a wealth of knowledge!The ChatBot developed by OpenAI was launched in November 2022 and subsequently caused a sensation and had a profound impact on various industries. The author started with a wait-and-see attitude, tried using it for a while, and eventually decided to join ChatGPT Plus. As a daily user of GPT, experiencing its benefits first-hand, it not only significantly accelerates the learning speed of individual technical knowledge and work efficiency but also brings benefits in other aspects of life. It is considered by the author to be the most directly helpful and least resistant new technology in recent years, after 3D printers, VR/AR, and Web3." name="description"><meta content="Would you like to understand the pitfalls encountered in developing OpenAI?Would you like to understand how to unlock Embeddings and Retrieval-Augmented Generation to enable GPT models to generate meaningful content, even without the unique know-how of enterprises? Then hurry up and click in, and leave with a wealth of knowledge!The ChatBot developed by OpenAI was launched in November 2022 and subsequently caused a sensation and had a profound impact on various industries. The author started with a wait-and-see attitude, tried using it for a while, and eventually decided to join ChatGPT Plus. As a daily user of GPT, experiencing its benefits first-hand, it not only significantly accelerates the learning speed of individual technical knowledge and work efficiency but also brings benefits in other aspects of life. It is considered by the author to be the most directly helpful and least resistant new technology in recent years, after 3D printers, VR/AR, and Web3." name="twitter:description"><meta content="Would you like to understand the pitfalls encountered in developing OpenAI?Would you like to understand how to unlock Embeddings and Retrieval-Augmented Generation to enable GPT models to generate meaningful content, even without the unique know-how of enterprises? Then hurry up and click in, and leave with a wealth of knowledge!The ChatBot developed by OpenAI was launched in November 2022 and subsequently caused a sensation and had a profound impact on various industries. The author started with a wait-and-see attitude, tried using it for a while, and eventually decided to join ChatGPT Plus. As a daily user of GPT, experiencing its benefits first-hand, it not only significantly accelerates the learning speed of individual technical knowledge and work efficiency but also brings benefits in other aspects of life. It is considered by the author to be the most directly helpful and least resistant new technology in recent years, after 3D printers, VR/AR, and Web3." property="og:description"><meta content="article" property="og:type"><meta content="https://tech-blog.cymetrics.io/en/posts/rayH/embeddings_rag/" property="og:url"><link href="https://tech-blog.cymetrics.io/en/posts/rayH/embeddings_rag/" rel="canonical"><meta content="Cymetrics Tech Blog" property="og:site_name"><meta content="https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/cover.png" property="og:image"><meta content="https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/cover.png" name="twitter:image"><meta content="hsZQwAip9iIbys-i4PJp_MfpNiA6w6RB0hYdWLiLUuk" name="google-site-verification"><meta content="always" name="referrer"><link href="/feed/feed.xml" rel="alternate" type="application/atom+xml" title="Cymetrics Tech Blog"><link href="/" rel="preconnect" crossorigin=""><script async="" src="/js/min.js?hash=7f26b2ece8" defer=""></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-3VBVCXV9Z0"></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-3VBVCXV9Z0');</script><script csp-hash="">if (/Mac OS X/.test(navigator.userAgent))document.documentElement.classList.add('apple')</script><style>:root{--primary-color: #5789d3;--primary-dark-color: #ffd349;--fgColor: #2f2f2f;--bgColor: linear-gradient(to top, #efefef, #ffffff);--primary: var(--primary-color);--primary-dark: var(--primary-dark-color);--fg: var(--fgColor);--bg: var(--bgColor);--progressColor: #ffd349;--main-width: calc(100vw - 3em)}main img{content-visibility:auto}article *{scroll-margin-top:50px}header nav{z-index:1;position:fixed;top:0;left:0;width:100vw;background:#fff;font-weight:200;text-align:right;padding:0}@media (min-width:37.5em){:root{--main-width: calc(37.5em - 3em)}}dialog,share-widget{position:fixed;opacity:.9}share-widget{right:20px;bottom:20px;width:50px;height:50px;border-radius:50%;overflow:hidden;box-shadow:2px 3px 5px 2px rgba(0,0,0,.2)}@media screen and (max-width:376px){share-widget{display:none}}share-widget div{margin-left:50%;transform:translateX(-50%);width:20px;height:20px;background-image:url(/img/share.svg);background-repeat:no-repeat;background-position:center;background-size:contain}.apple share-widget div{background-image:url(/img/share-apple.svg)}share-widget button{margin:0;padding:0;width:100%;height:100%;transition:.3s}share-widget button:active{transform:scale(1.2)}dialog{background-color:var(--primary-dark);z-index:1000;font-size:14px}#reading-progress{z-index:1;background-color:var(--progressColor);width:100vw;position:absolute;left:0;bottom:0;height:2px;transform:translate(-100vw,0);will-change:transform;pointer-events:none}#posts li{margin-bottom:.5em}button,html{line-height:1.15}html{-webkit-text-size-adjust:100%;font-family:"Open Sans",-apple-system,system-ui,BlinkMacSystemFont,"Segoe UI",Roboto,"Noto Sans","Helvetica Neue",Helvetica,Arial,"Noto Sans TC","PingFang TC","Hiragino Sans GB","Heiti TC","Microsoft YaHei","Microsoft Jhenghei",sans-serif;--font-family: "Open Sans", -apple-system, system-ui, BlinkMacSystemFont,
    "Segoe UI", Roboto, "Noto Sans", "Helvetica Neue", Helvetica, Arial,
    "Noto Sans TC", "PingFang TC", "Hiragino Sans GB", "Heiti TC",
    "Microsoft YaHei", "Microsoft Jhenghei", sans-serif}body{margin:0}body.lock{overflow:hidden}a{background-color:transparent;text-underline-offset:2px;text-decoration:none;color:var(--primary)}b,strong{font-weight:700}img{border-style:none;max-width:100%;height:auto;margin:0 auto}button{font-family:inherit;font-size:100%;overflow:visible;text-transform:none}[type=button],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}h2{font-size:2.5em;line-height:1.2;margin-bottom:.6em;line-height:2.4rem;margin-bottom:1.36rem;font-size:1.728rem}h3{font-size:2em;line-height:1.125;margin-bottom:.75em;font-size:1.4rem;line-height:1.5rem;margin-bottom:1rem}body,ol,p,ul{font-size:1em}form,ol,p,ul{margin-bottom:1.5em}body,ol,p,ul{font-size:1rem;line-height:1.6}ol,p,ul{margin-bottom:1.36rem}@media (min-width:600px){h2{font-size:2.0097rem;line-height:2.52rem}h3{font-size:1.7989rem;line-height:2rem}body,ol,p,ul{font-size:1.1rem;line-height:1.6}h2,h3,ol,p,ul{margin-bottom:1.496rem}}@media (min-width:1200px){h2{font-size:2.05rem}h3{font-size:1.5rem}body,ol,p,ul{font-size:1.2rem;line-height:1.6}h2,h3,ol,p,ul{margin-bottom:1.632rem}}h1,h2,h3{font-family:var(--font-family)}a:hover{text-decoration:underline}form{padding:1.5em 1.5em 0;border:.2rem solid #202020}button{border-radius:.3em;max-width:100%;background:#f2f2f2;color:#191919;cursor:pointer;padding:.75em 1.5em;text-align:center;margin:0 .75em 1.5em 0}button+label,label+*{page-break-before:always}button,label{display:inline-block}form>:not(fieldset){margin-right:.75em}button:hover{background:#d9d9d9;color:#000}button:not([disabled]){background:#f9c412;color:#181818;background:var(--primary)}button:not([disabled]):hover{background:#ba9005;color:#000;background:var(--primary-dark)}*{border:0;box-sizing:border-box}body{font-family:var(--font-family);background:var(--bg);color:var(--fg)}header label{display:block}article,header{max-width:100%;width:42.5em;margin:0 auto}header{padding:4.5em 24px 0;text-align:center;display:flex;align-items:center;flex-direction:column}header p,ol,ul{margin-top:0}header nav .nav-title{float:left;font-size:inherit;line-height:inherit;margin:0;text-align:left}header nav label{color:#000;cursor:pointer;margin:0;font-style:normal;text-align:right}main{max-width:70rem;margin:0 auto;min-height:60vh}article{padding:1.5em;word-break:break-word}li ol,li ul{margin-bottom:0}.token.function,.token.number{color:#f08d49}.token.property{color:#f8c555}.token.url{color:#67cdcc}.token.bold{font-weight:700}.token.inserted{color:green}::-webkit-scrollbar-thumb:hover{background:var(--primary)}.w-full{width:100%}body.dark{--fg: var(--bgColor);--bg: var(--fgColor);--primary: var(--primary-dark-color)}@media (prefers-color-scheme:dark){body.dark{--fg: var(--bgColor);--bg: var(--fgColor);--primary: var(--primary-dark-color)}}h1{font-size:32px;line-height:1.25;margin:.67em 0;text-align:left}header aside{font-size:16px;color:#4b4b4b}.post,footer{border-top:1px solid #ccc}.post{padding-top:35px;margin-top:35px}.menu__btn{display:inline-block;width:24px;height:24px;position:relative}.menu__btn span{opacity:0;width:1px;height:1px;overflow:hidden;display:block}.menu__btn::after,.menu__btn::before{content:"";position:absolute;top:51%;left:50%;height:2px;width:17px;background-color:#2d2d2d;border-radius:.1rem}.menu__btn::before{transform:translate(-50%,-50%);box-shadow:0 .3rem 0 #2d2d2d,0 -.3rem 0 #2d2d2d}.menu__btn::after{display:none;transform:translate(-50%,-50%) rotate(90deg)}.menu__btn.menu__btn--close{z-index:9;transform:rotate(45deg)}.menu__btn.menu__btn--close::before{box-shadow:none}.menu__btn.menu__btn--close::after{display:block}#nav,#nav .nav-title{display:flex;align-items:center}#nav{position:relative;height:68px;z-index:2}#nav .nav-title{padding:.375rem 1.5rem;width:100%;justify-content:space-between}#nav .nav-title *,.article-footer img{margin:0}.nav__links{display:none;flex-direction:column;position:fixed;z-index:3;top:0;left:0;right:0;bottom:0;padding:86px 48px 0;background-image:linear-gradient(to top,#efefef,#fff),linear-gradient(to bottom,#f9f9f9,#f9f9f9)}.nav__links--open{display:flex}.nav__links a{text-align:left;width:100%;padding:.5rem 0;transition:all .3s ease-out;font-weight:700;text-decoration:none;color:var(--fg)}.nav__links a:hover{color:var(--primary-color)}.nav-logo{width:260px;height:40px;background:url(/img/logo1.png) no-repeat center center;background-size:contain}footer{margin-top:48px;font-size:14px;padding:24px;text-align:center}.copyright{display:inline-block}footer>*{margin:.5em}.footer-logos{display:flex;align-items:center;justify-content:center}.footer-logos a:not(:first-child){margin-left:32px}.post-tags{display:flex;gap:0 16px;flex-wrap:wrap}.direct-link{display:none}.post-avatar{margin-top:27px;display:flex;align-items:center;height:36px}.post-avatar__img{width:36px;height:36px;overflow:hidden;margin:0;border-radius:50%}.post-avatar__time{font-size:13px}.post-avatar__info{margin-left:8px;color:#747474;text-align:left}.post-avatar__author{font-size:14px;font-weight:700}.article-footer{margin-top:40px;border-bottom:1px solid #ccc;padding-bottom:52px}.article-footer a{float:right;display:flex;align-items:center;color:var(--fg);font-weight:700;margin-left:4px}.article-author{margin-top:34px;display:flex;align-items:flex-start;margin-bottom:48px}.article-author__img{width:80px;height:80px;overflow:hidden;margin:0;border-radius:50%;flex-shrink:0}.article-author__info{margin-left:16px;text-align:left}.article-author__title{color:#747474;font-size:16px}.article-author__author{font-size:22px;font-weight:700;line-height:1em}.article-author__intro{color:#2f2f2f;margin-top:8px}@media (min-width:768px){h1{font-size:48px}header aside{font-size:20px}header nav a:first-of-type{margin-left:auto}header nav a:last-of-type{margin-right:1.5em}.menu__btn{display:none}#nav,footer{max-width:1168px}#nav{height:80px;margin:0 auto}.nav-logo{width:313px}.nav__links{display:flex;flex-direction:row;position:static;padding:0;background-image:none}.nav__links a{text-align:center;margin-left:56px}footer{display:flex;flex-direction:row-reverse;justify-content:space-between;align-items:center;margin-left:auto;margin-right:auto}}.notice-block{text-align:left;background:rgba(87,137,211,.2);padding:16px;margin-top:24px;border-radius:8px}</style></head><body><header><nav><div id="nav"><div class="nav-title"><a href="/" class="nav-logo" title="Homepage"></a> <label class="menu__btn" for="menu__control"><span>Menu</span></label></div><div class="nav__links"><a href="/archive/">Archive</a> <a href="/tags/">Tags</a> <a href="/about/">About</a> <a href="/en">English</a></div></div><div id="reading-progress" aria-hidden="true"></div></nav><h1 class="w-full">Practical Applications and Challenges of OpenAI Embeddings and Retrieval-Augmented Generation</h1><aside class="w-full"><div class="post-tags"><a href="/tags/postsen/" class="post-tag">#postsEn</a> <a href="/tags/openai/" class="post-tag">#OpenAI</a> <a href="/tags/chatgpt/" class="post-tag">#ChatGPT</a> <a href="/tags/embeddings/" class="post-tag">#Embeddings</a> <a href="/tags/rag/" class="post-tag">#RAG</a></div><div class="post-avatar"><img alt="rayH" src="/img/authors/ray_logo.jpeg" class="post-avatar__img" data-deopt="true"><div class="post-avatar__info"><div class="post-avatar__author"><a href="/posts/rayH">rayH</a></div><div class="post-avatar__time">25 Aug 2023</div></div></div><div class="notice-block" data-nosnippet="" style="display:none;">我們正在尋找一位 Security Engineer 加入我們的團隊，詳情請參考<a href="https://github.com/cymetrics/blog/issues/13" rel="noopener noreferrer" target="_blank">職缺資訊</a></div></aside><dialog id="message"></dialog></header><main><article><div id="post-page"></div><p>Would you like to understand the pitfalls encountered in developing OpenAI?<br>Would you like to understand how to unlock Embeddings and Retrieval-Augmented Generation to enable GPT models to generate meaningful content, even without the unique know-how of enterprises? Then hurry up and click in, and leave with a wealth of knowledge!</p><p>The ChatBot developed by OpenAI was launched in November 2022 and subsequently caused a sensation and had a profound impact on various industries. The author started with a wait-and-see attitude, tried using it for a while, and eventually decided to join ChatGPT Plus. As a daily user of GPT, experiencing its benefits first-hand, it not only significantly accelerates the learning speed of individual technical knowledge and work efficiency but also brings benefits in other aspects of life. It is considered by the author to be the most directly helpful and least resistant new technology in recent years, after 3D printers, VR/AR, and Web3.</p><h2 id="preface"><a href="#preface" class="direct-link">#</a> Preface</h2><p>The ChatBot developed by OpenAI was launched in November 2022, and it has had a profound impact and caused a sensation across various industries. The author began with a wait-and-see attitude, experimented with it for a while, and finally decided to join ChatGPT Plus. As someone who uses GPT daily, the author has personally experienced its advantages. It can substantially accelerate learning in personal technical knowledge and improve work efficiency and can also assist in other aspects of life. It is considered one of the most directly helpful and frictionless new technologies in recent years, following 3D printers, VR/AR, and Web3.</p><p>Cymetrics is also aiming to leverage the trend of AI to provide better services and values to clients with their cybersecurity products. Hence, the author had this opportunity to implement AI products. The first version MVP of our AI service has been released, so the author has time to write articles and make a summary. Since the author does not have a background in AI, any inaccuracies in wording are open for correction and discussion.</p><h2 id="what-have-we-learned%3F"><a href="#what-have-we-learned%3F" class="direct-link">#</a> What Have We Learned?</h2><p>In this article, a straightforward introduction will mainly be given to the following topics:</p><ol><li>Basic introduction to OpenAI embeddings</li><li>Brief overview of RAG</li><li>Difficulties encountered in implementing AI in practice</li></ol><p>Hopefully, after reading this article, developers who wish to use RAG and embeddings will gain a better understanding.</p><h2 id="why"><a href="#why" class="direct-link">#</a> Why</h2><p>Motivation is the core part of why we do something, and engineering is the means to satisfy this motivation. So, clarifying the motivation is quite necessary before discussing the more technical aspects.</p><p>From the perspective of some enterprises, the desired applications are usually not just simple Q&A. More often, they involve some complex requirements, which might generally include the following issues:</p><ol><li>Current GPT models lack company-specific industry knowledge</li><li>The knowledge of OpenAI’s GPT is only up to September 2021</li></ol><p>These problems might lead users to receive seemingly logical but not so accurate content from GPT, known as "hallucination" in generative AI. To solve the above problems, we have used RAG and embeddings to meet our business needs.</p><h2 id="what"><a href="#what" class="direct-link">#</a> What</h2><p>So, what exactly are embeddings and RAG?</p><h3 id="embeddings"><a href="#embeddings" class="direct-link">#</a> Embeddings</h3><p>Embeddings are a means of vectorizing text, as shown in the following diagram.</p><p><picture><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/embedding_vector-1920w.webp 1920w, /img/posts/rayH/embeddings_rag/embedding_vector-1280w.webp 1280w, /img/posts/rayH/embeddings_rag/embedding_vector-840w.webp 840w, /img/posts/rayH/embeddings_rag/embedding_vector-320w.webp 320w" type="image/webp"><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/embedding_vector-1920w.png 1920w, /img/posts/rayH/embeddings_rag/embedding_vector-1280w.png 1280w, /img/posts/rayH/embeddings_rag/embedding_vector-840w.png 840w, /img/posts/rayH/embeddings_rag/embedding_vector-320w.png 320w" type="image/png"><img alt="" src="/img/posts/rayH/embeddings_rag/embedding_vector-1920w.png" height="698" width="2022" decoding="async" loading="lazy" style="background-size:cover;background-image:url(&#34;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 2022 698'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA0AAAAFCAYAAACeuGYRAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAh0lEQVQYlW1PywrDIBD0///MWzxJICheRDCXIMZX4pRdKDRtB4ZlWeaxAgDu+0bvneec88F/ELVWaK0hpWTRJ0hE9+u6HkZiWRY452CM4bQYI0II8N6z8DgOxH3HeZ7IOSOlBEGLtRZKKRa11lBKYVLKGIMiOY2aEAW5bduGdV1/un/Xff/0ApGN/CIneNI7AAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&#34;)"></picture></p><p>In life, sometimes, we need to clarify the similarity between objects, for example: Are apples and bananas similar? Generally, this kind of question can be answered in less than a second. But when the question becomes, please compare the similarity of these two paragraphs of text? If both paragraphs are unseen, the likely answer will be, "Let me take a quick look before I can distinguish," and an answer might be available five minutes later.</p><p>But what if the condition becomes "Regardless of the amount of text, the similarity of this text needs to be informed within one second?"</p><p><picture><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/question-1920w.webp 1920w, /img/posts/rayH/embeddings_rag/question-1280w.webp 1280w, /img/posts/rayH/embeddings_rag/question-840w.webp 840w, /img/posts/rayH/embeddings_rag/question-320w.webp 320w" type="image/webp"><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/question-1920w.png 1920w, /img/posts/rayH/embeddings_rag/question-1280w.png 1280w, /img/posts/rayH/embeddings_rag/question-840w.png 840w, /img/posts/rayH/embeddings_rag/question-320w.png 320w" type="image/png"><img alt="" src="/img/posts/rayH/embeddings_rag/question-1920w.png" height="810" width="986" decoding="async" loading="lazy" style="background-size:cover;background-image:url(&#34;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 986 810'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAHCAYAAADam2dgAAAACXBIWXMAABYlAAAWJQFJUiTwAAABAklEQVQYlRXKPUsCcQDA4f9HaexTtDR1DQ5hQVBQUUGbS1MYRosYUYTmSRQOh4rS4YV3asdZVmS+nYph3mm1SRFCfoFf9MyPeOtVqOkprHIFaU5idnoK5TzEeDLidzKipCcQZsyPqUTRtAI+aYb0hoeTLS+Vcg69cIORCiOKlwfk5RCdWpPophd5WSK86uFeT9Bzu9xpcYRxEWBve42cYXKbSXK6ssDhkgc1KfP++cq1EkNkI37OdnfIXkUoqhmO170EFucp5S1abZt4OPif9qlaaewnnebzC53HBk57QN/5omX3aVTriPSRj/qDSq87wHG+cYdj+u4PbfuDVnNIMqHyB5cau4TzaQFWAAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&#34;)"></picture></p><p>Vectors can easily accomplish comparisons of similarity. Whether a vector is similar depends on the direction and magnitude of the vector. Therefore, one can easily discern the degree of similarity between vectors based on their direction. For instance, as shown in the following diagram, most people can tell within a second that vector A and vector B are not the same.</p><p><picture><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/vectorr-1920w.webp 1920w, /img/posts/rayH/embeddings_rag/vectorr-1280w.webp 1280w, /img/posts/rayH/embeddings_rag/vectorr-840w.webp 840w, /img/posts/rayH/embeddings_rag/vectorr-320w.webp 320w" type="image/webp"><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/vectorr-1920w.png 1920w, /img/posts/rayH/embeddings_rag/vectorr-1280w.png 1280w, /img/posts/rayH/embeddings_rag/vectorr-840w.png 840w, /img/posts/rayH/embeddings_rag/vectorr-320w.png 320w" type="image/png"><img alt="" src="/img/posts/rayH/embeddings_rag/vectorr-1920w.png" height="390" width="374" decoding="async" loading="lazy" style="background-size:cover;background-image:url(&#34;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 374 390'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAYAAADED76LAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAiElEQVQYlVVP7Q6DIAzk/Z9w2b/FZJMFRKAiU9pbRNHtkjZN7itVACAidRpSSiCieqtKHgSXBbO7wzuNEA5B3VKQ6YkcO6x5PJM2s8qfCGdvkHX6I1qlYi4wpGHoDRHeq4QvQXNNOaD3HdJC8C5gsMNe8Ru3OU3s8RofKFyuL1pvgyWNvM5V8AWBpvr7a4eBOAAAAABJRU5ErkJggg=='%3E%3C/image%3E%3C/svg%3E&#34;)"></picture></p><p>With this concept in mind, it’s not hard to understand why embeddings are needed. As mentioned above, embeddings are essentially a means to vectorize text. So, once the text is converted into vectors, we can very quickly compare the degree of similarity between texts through vector comparison.</p><p>However, we also need to consider the dimension of the vector. If a vector is only one-dimensional, is it easy to distinguish? For example, the one-dimensional vectors below seem to be the same, but they are not. Although the direction is the same, the magnitude of the vectors differs slightly.</p><p><picture><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/vectorrrr-1920w.webp 1920w, /img/posts/rayH/embeddings_rag/vectorrrr-1280w.webp 1280w, /img/posts/rayH/embeddings_rag/vectorrrr-840w.webp 840w, /img/posts/rayH/embeddings_rag/vectorrrr-320w.webp 320w" type="image/webp"><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/vectorrrr-1920w.png 1920w, /img/posts/rayH/embeddings_rag/vectorrrr-1280w.png 1280w, /img/posts/rayH/embeddings_rag/vectorrrr-840w.png 840w, /img/posts/rayH/embeddings_rag/vectorrrr-320w.png 320w" type="image/png"><img alt="" src="/img/posts/rayH/embeddings_rag/vectorrrr-1920w.png" height="316" width="1152" decoding="async" loading="lazy" style="background-size:cover;background-image:url(&#34;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 1152 316'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAECAYAAABREWWJAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAZElEQVQImWP4TwFg+P3n1/+P397+//TtHSr+jozf///47d3/Lz8+/X/6/t7/B6+v/f/3799/BpDE5cfH/195cgIJn4Tjq09PgfGVJ6f+33x+4f+BGxv+bzo3+//v3z/+M1DibAAU+uWoydRkYQAAAABJRU5ErkJggg=='%3E%3C/image%3E%3C/svg%3E&#34;)"></picture></p><p>Thus, the dimensionality of vectors is also a factor in determining the degree of similarity. If the vector dimension is too low, it may lead to high resemblance between vectors that are not inherently very similar, due to the low dimensionality (as shown in the above one-dimensional array), increasing the margin of error. Currently, the vector dimension for embeddings provided by OpenAI is 1536, while for Bert-base it is 768, and for Bert-large, it is 1024. With the increase in vector dimensions, it is not hard to understand that the probability of vectors being close to or intersecting with each other becomes increasingly lower, unless they have a certain degree of similarity.</p><p>In conclusion:</p><ol><li>Embeddings are primarily a means of vectorizing text.</li><li>The time cost of comparing vectorized entities is very low.</li><li>The number of dimensions in embeddings, in some cases, can affect the error rate of text similarity.</li></ol><h3 id="retrieval-augmented-generation-(rag)"><a href="#retrieval-augmented-generation-(rag)" class="direct-link">#</a> <strong><strong>Retrieval Augmented Generation (RAG)</strong></strong></h3><p>The concept of RAG originated from a paper (<a href="https://arxiv.org/abs/2005.11401" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2005.11401</a>). We will not delve into explaining the core idea of the author here. Interested readers can study the paper themselves. Our focus here is on how to apply the concept of RAG in generative AI and what specific problems it solves.</p><p><picture><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/rag-1920w.webp 1920w, /img/posts/rayH/embeddings_rag/rag-1280w.webp 1280w, /img/posts/rayH/embeddings_rag/rag-840w.webp 840w, /img/posts/rayH/embeddings_rag/rag-320w.webp 320w" type="image/webp"><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/rag-1920w.png 1920w, /img/posts/rayH/embeddings_rag/rag-1280w.png 1280w, /img/posts/rayH/embeddings_rag/rag-840w.png 840w, /img/posts/rayH/embeddings_rag/rag-320w.png 320w" type="image/png"><img alt="" src="/img/posts/rayH/embeddings_rag/rag-1920w.png" height="1042" width="2130" decoding="async" loading="lazy" style="background-size:cover;background-image:url(&#34;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 2130 1042'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAFCAYAAACTphZWAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAp0lEQVQImW2PSwrCMABEc/+DeARxp4IKivjXWim4aFJrk1grEWxr+kQFV85q3iwejOj2+mRaE0uJUglSJSilmCxD1vsIKWPmq4D1JkAE4YF/GRxLItt8euIgv1eI9mBB6hp8XdGankmuJRdrKF0OePCeXeqITYGYLTc/28necI8aGk8vvJI/vnsFlPUTMRyOuBUF6TlDZxlGa4wxdMYh2yjmYu2H3z9e+CfNr4h1gZAAAAAASUVORK5CYII='%3E%3C/image%3E%3C/svg%3E&#34;)"></picture></p><p>(<a href="https://github.com/Azure-Samples/azure-search-openai-demo" rel="noopener noreferrer" target="_blank">https://github.com/Azure-Samples/azure-search-openai-demo</a>)</p><p>The image above is from the azure-search-openai-demo repository. This repository utilizes the spirit of RAG in conjunction with OpenAI's generative AI to solve the problems mentioned above. Before explaining this image, let’s clarify our business objective again: “GPT can answer based on our company’s proprietary industry knowledge and data post-September 2021.” To achieve this, if we do not use model training, we inevitably have to add possible answers before the client’s prompt and then send this content into OpenAI, hoping GPT can give us an answer with high precision.</p><p>Mapping the above process to the image, first, users will ask questions through a terminal device. Then we will take the path above. We will try to find possible answers in our enterprise database based on user questions or search for solutions using a search engine. Next, we will take the path below. We will send the user's question and the possible answers found to OpenAI. Thus, the data GPT relies on when answering user questions will not only be the unique knowhow of the enterprise and the latest information but also can effectively reduce the degree of GPT hallucination.</p><h1 id="how"><a href="#how" class="direct-link">#</a> How</h1><p>From the above discussion, we can now understand the preliminary concepts of RAG and embeddings. Next, we will discuss how to implement the detailed parts using the ideas above. Details are as follows:</p><ol><li>Vectorize the company's industry knowledge and the latest relevant online information using OpenAI's embeddings API and upload the vector results to a vector database (e.g., Pinecone).</li><li>Obtain a set of vectors for the user's question using OpenAI's embeddings API. Remember, this set of vectors is essentially approximate to the question asked by the user. It's just expressed in another form.</li><li>Then, use the vector obtained in step two to query the vector database.</li><li>The vector database will, based on the initially set matching rules, give the texts inside the vectors "closest" to the user's question vector (this text content will be from the industry knowhow vectorized by the enterprise initially).</li><li>This text content will be combined with the user's question into one prompt, sent into OpenAI GPT, and we will wait for GPT's answer.</li></ol><p>The above are the more detailed parts of combining RAG with embeddings. Through this process, GPT can answer based on the enterprise’s knowhow or events occurring after September 2021.</p><h2 id="practical-issues"><a href="#practical-issues" class="direct-link">#</a> Practical Issues</h2><p>Although RAG and embeddings seem promising, there is still a considerable distance from true commercialization. If we want to substantially improve the precision of the answers, significant time investment is also needed. Below are the issues encountered in practical development.</p><h3 id="1.-data-for-embeddings-may-need-prior-organization"><a href="#1.-data-for-embeddings-may-need-prior-organization" class="direct-link">#</a> 1. Data for embeddings may need prior organization</h3><p>The format of the data sent into embeddings may affect the results after embeddings. From current practical experience, we have used CSV and JSON-formatted data, but the final results of embeddings seem no better than those obtained after data cleaning and merging.</p><h3 id="2.-token-number-and-cost"><a href="#2.-token-number-and-cost" class="direct-link">#</a> 2. Token number and cost</h3><p>The vector database is an additional cost. Also, the number of tokens sent into OpenAI may consist of historical information, information retrieved from the vector database, basic background information, etc., so cost considerations must also be clear and reasonable. Due to the peculiarities of our business, our prompts' token numbers may start in the tens of thousands.</p><h3 id="3.-error"><a href="#3.-error" class="direct-link">#</a> 3. Error</h3><p>Error is the greatest enemy of precision; it might come from several aspects:</p><ul><li>Embeddings</li></ul><p>Embeddings have a certain error. One possible reason for the error is the strategy chosen for vector similarity matching; it might also be the format or content of the data sent into embeddings.</p><ul><li>Inherent nature of language generation</li></ul><p>Through the technique of embeddings, grabbing the most relevant enterprise knowhow text, GPT will also give conclusions with a slight deviation to a certain extent. It might be improved using top_p or temperature, but if these two values are too low, the text output by GPT will be too similar to the original text of the enterprise, which usually is not a desirable result, so how to choose is another problem.</p><ul><li>Need to split if the prompt is too long</li></ul><p>Both embeddings and prompt have a single handling token limit. But when your text is too large, it needs to be split. Through the split text, the context is usually not complete, so additional supplementary processing is needed, and finally, the results generated by GPT also need separate merging. But even so, it will still cause a decline in precision.</p><h3 id="4.-quality-and-response-speed"><a href="#4.-quality-and-response-speed" class="direct-link">#</a> 4. Quality and response speed</h3><p>From current actual testing, the more rules are limited in the prompt, the longer the response time seems to be. Moreover, due to the inherent randomness of GPT, often we don’t have only one layer of Q&ampA; a customer's question might have three interactions with GPT. For instance, the first layer might be filtering the type of user's question, then different models are used to process according to different types (including parameters, model selection), and finally, it is for quality control or supplement. This series of operations done for output quality will cause a prolongation of response time.</p><h3 id="5.-language-issues"><a href="#5.-language-issues" class="direct-link">#</a> 5. Language issues</h3><p>Even if the language is specified in the prompt, and some strong tone keywords are used to inform GPT of the reply language, the output results sometimes will still be unexpected. A possible reason is that the training data of the original model covered various languages, so when outputting the answers, it inherently might include Chinese and English. So, different languages might occur in the output.</p><h2 id="conclusion"><a href="#conclusion" class="direct-link">#</a> Conclusion</h2><p>In this article, we have some common explanations about RAG search and embeddings and share the challenges we encountered in developing AI. We hope these things can help everyone avoid some pitfalls in developing AI. Due to the length of the article, many places are only mentioned briefly. If the response is good, we will subsequently provide more interesting articles on AI topics.</p><div class="article-footer"><a href="https://tech-blog.cymetrics.io/en/posts/rayH/embeddings_rag/" on-click="share"><img alt="Share" src="/img/icons/icon_external link hyperlink.svg" height="24" width="24">Share this post</a></div><div><p style="font-weight: bold;">Tag</p><div class="post-tags"><a href="/tags/postsen/" class="post-tag">#postsEn</a> <a href="/tags/openai/" class="post-tag">#OpenAI</a> <a href="/tags/chatgpt/" class="post-tag">#ChatGPT</a> <a href="/tags/embeddings/" class="post-tag">#Embeddings</a> <a href="/tags/rag/" class="post-tag">#RAG</a></div><p style="font-weight: bold;">Recommendation</p><ol><li><a href="/posts/cymetrics/spring4shell-critical-java-rce-0day/">Spring4shell 來襲！繼 Log4Shell 後又一 Java 生態系嚴重漏洞出現</a></li><li><a href="/posts/zet/uuid-shellcode-loader/">跟端點防護軟體玩玩貓捉老鼠的遊戲 - Shellcode loader</a></li><li><a href="/posts/nick/owasp-cwe/">資安規範實戰篇 : OWASP + CWE</a></li><li><a href="/posts/jo/zerobased-path-traversal/">零基礎資安系列（五）-路徑遍歷（Path Traversal）</a></li><li><a href="/posts/jo/zerobased-cross-site-scripting/">零基礎資安系列（二）-認識 XSS（Cross-Site Scripting）</a></li></ol></div><div class="article-author"><img alt="rayH" src="/img/authors/ray_logo.jpeg" class="article-author__img" data-deopt="true"><div class="article-author__info"><div class="article-author__title">Author</div><div class="article-author__author"><a href="/posts/rayH">rayH</a></div><div class="article-author__intro">Software Engineer</div></div></div><p style="font-weight: bold;">Discussion(login required)</p><script async="" src="https://utteranc.es/client.js" crossorigin="anonymous" id="utterance-script" issue-term="title" label="utterance" repo="cymetrics/blog" theme="github-light"></script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Practical Applications and Challenges of OpenAI Embeddings and Retrieval-Augmented Generation","image":["https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/embedding_vector-1920w.png","https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/question-1920w.png","https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/vectorr-1920w.png","https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/vectorrrr-1920w.png","https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/rag-1920w.png","https://tech-blog.cymetrics.io/img/icons/icon_external link hyperlink.svg","https://tech-blog.cymetrics.io/img/authors/ray_logo.jpeg"],"author":{"@type":"Person","name":"rayH"},"publisher":{"@type":"Organization","name":"Cymetrics Tech Blog","url":"https://tech-blog.cymetrics.io","logo":{"@type":"ImageObject","url":"https://tech-blog.cymetrics.io/img/favicon/favicon-512x512.png","width":512,"height":512}},"url":"https://tech-blog.cymetrics.io/en/posts/rayH/embeddings_rag/","mainEntityOfPage":"https://tech-blog.cymetrics.io/en/posts/rayH/embeddings_rag/","datePublished":"2023-08-25","dateModified":"2023-10-02","description":"Would you like to understand the pitfalls encountered in developing OpenAI? Would you like to understand how to unlock Embeddings and..."}</script></article></main><footer><div class="footer-logos"><a href="https://www.facebook.com/cymetrics" rel="noopener noreferrer" target="_blank"><img alt="facebook" src="/img/icons/icon_social media_facebook.svg" height="30" width="30"></a><a href="https://www.linkedin.com/company/cymetrics" rel="noopener noreferrer" target="_blank"><img alt="linkedin" src="/img/icons/icon_social media_linkedln.svg" height="30" width="30"></a><a href="https://tech-blog.cymetrics.io/feed/feed.xml" rel="noreferrer noopener" target="_blank"><img alt="rss feed" src="/img/icons/rss-feed.svg" height="30" width="30"></a></div><div class="copyright">© 2021 Cymetrics Tech Blog, based on <a href="https://github.com/google/eleventy-high-performance-blog" rel="noopener noreferrer" target="_blank">eleventy-high-performance-blog</a>. <a href="https://oneinfinity.global/" rel="noopener noreferrer" target="_blank">OneInfinity</a></div></footer><script>// light/dark theme switch
      // disable dark mode for now
      const menuBtn = document.querySelector('.menu__btn')
      menuBtn.addEventListener('click', function() {
        document.querySelector('body').classList.toggle('lock')
        menuBtn.classList.toggle('menu__btn--close');
        document.querySelector('.nav__links').classList.toggle('nav__links--open')
      })</script></body></html>