<!DOCTYPE html><html domain="tech-blog.cymetrics.io" ga-id="G-3VBVCXV9Z0" lang="zh-TW"><head><meta charset="utf-8"><meta content="width=device-width,initial-scale=1" name="viewport"><meta content="CYBER,Cymetrics,Security" name="keywords"><link href="/img/favicon/favicon-192x192.png?hash=42b087227d" rel="icon" type="image/png"><meta content="#5789d3" name="theme-color"><title>OpenAI Embeddings 與 Retrieval-Augmented Generation在實務中的應用與挑戰</title><meta content="OpenAI Embeddings 與 Retrieval-Augmented Generation在實務中的應用與挑戰" property="og:title"><meta content="OpenAI Embeddings 與 Retrieval-Augmented Generation在實務中的應用與挑戰" name="twitter:title"><meta content="summary_large_image" name="twitter:card"><meta content="想了解開發 OpenAI 會遇到哪一些坑嗎？想了解如何解鎖 Embeddings 和 Retrieval-Augmented Generation 讓 GPT 的模型就算沒有企業獨有的 knowhow，也能產生出有意義的內容嗎？那就快點手刀點進來吧，讓您滿載而歸！" name="description"><meta content="想了解開發 OpenAI 會遇到哪一些坑嗎？想了解如何解鎖 Embeddings 和 Retrieval-Augmented Generation 讓 GPT 的模型就算沒有企業獨有的 knowhow，也能產生出有意義的內容嗎？那就快點手刀點進來吧，讓您滿載而歸！" name="twitter:description"><meta content="想了解開發 OpenAI 會遇到哪一些坑嗎？想了解如何解鎖 Embeddings 和 Retrieval-Augmented Generation 讓 GPT 的模型就算沒有企業獨有的 knowhow，也能產生出有意義的內容嗎？那就快點手刀點進來吧，讓您滿載而歸！" property="og:description"><meta content="article" property="og:type"><meta content="https://tech-blog.cymetrics.io/posts/rayH/embeddings_rag/" property="og:url"><link href="https://tech-blog.cymetrics.io/posts/rayH/embeddings_rag/" rel="canonical"><meta content="Cymetrics Tech Blog" property="og:site_name"><meta content="https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/cover.png" property="og:image"><meta content="https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/cover.png" name="twitter:image"><meta content="hsZQwAip9iIbys-i4PJp_MfpNiA6w6RB0hYdWLiLUuk" name="google-site-verification"><meta content="always" name="referrer"><link href="/feed/feed.xml" rel="alternate" type="application/atom+xml" title="Cymetrics Tech Blog"><link href="/" rel="preconnect" crossorigin=""><script async="" src="/js/min.js?hash=7f26b2ece8" defer=""></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-3VBVCXV9Z0"></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-3VBVCXV9Z0');</script><script csp-hash="">if (/Mac OS X/.test(navigator.userAgent))document.documentElement.classList.add('apple')</script><style>:root{--primary-color: #5789d3;--primary-dark-color: #ffd349;--fgColor: #2f2f2f;--bgColor: linear-gradient(to top, #efefef, #ffffff);--primary: var(--primary-color);--primary-dark: var(--primary-dark-color);--fg: var(--fgColor);--bg: var(--bgColor);--progressColor: #ffd349;--main-width: calc(100vw - 3em)}main img{content-visibility:auto}article *{scroll-margin-top:50px}header nav{z-index:1;position:fixed;top:0;left:0;width:100vw;background:#fff;font-weight:200;text-align:right;padding:0}@media (min-width:37.5em){:root{--main-width: calc(37.5em - 3em)}}dialog,share-widget{position:fixed;opacity:.9}share-widget{right:20px;bottom:20px;width:50px;height:50px;border-radius:50%;overflow:hidden;box-shadow:2px 3px 5px 2px rgba(0,0,0,.2)}@media screen and (max-width:376px){share-widget{display:none}}share-widget div{margin-left:50%;transform:translateX(-50%);width:20px;height:20px;background-image:url(/img/share.svg);background-repeat:no-repeat;background-position:center;background-size:contain}.apple share-widget div{background-image:url(/img/share-apple.svg)}share-widget button{margin:0;padding:0;width:100%;height:100%;transition:.3s}share-widget button:active{transform:scale(1.2)}dialog{background-color:var(--primary-dark);z-index:1000;font-size:14px}#reading-progress{z-index:1;background-color:var(--progressColor);width:100vw;position:absolute;left:0;bottom:0;height:2px;transform:translate(-100vw,0);will-change:transform;pointer-events:none}#posts li{margin-bottom:.5em}button,html{line-height:1.15}html{-webkit-text-size-adjust:100%;font-family:"Open Sans",-apple-system,system-ui,BlinkMacSystemFont,"Segoe UI",Roboto,"Noto Sans","Helvetica Neue",Helvetica,Arial,"Noto Sans TC","PingFang TC","Hiragino Sans GB","Heiti TC","Microsoft YaHei","Microsoft Jhenghei",sans-serif;--font-family: "Open Sans", -apple-system, system-ui, BlinkMacSystemFont,
    "Segoe UI", Roboto, "Noto Sans", "Helvetica Neue", Helvetica, Arial,
    "Noto Sans TC", "PingFang TC", "Hiragino Sans GB", "Heiti TC",
    "Microsoft YaHei", "Microsoft Jhenghei", sans-serif}body{margin:0}body.lock{overflow:hidden}a{background-color:transparent;text-underline-offset:2px;text-decoration:none;color:var(--primary)}b,strong{font-weight:700}img{border-style:none;max-width:100%;height:auto;margin:0 auto}button{font-family:inherit;font-size:100%;overflow:visible;text-transform:none}[type=button],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}h2{font-size:2.5em;line-height:1.2;margin-bottom:.6em;line-height:2.4rem;margin-bottom:1.36rem;font-size:1.728rem}h3{font-size:2em;line-height:1.125;margin-bottom:.75em;font-size:1.4rem;line-height:1.5rem;margin-bottom:1rem}body,ol,p,ul{font-size:1em}ol,p,ul{margin-bottom:1.5em}body,ol,p,ul{font-size:1rem;line-height:1.6}ol,p,ul{margin-bottom:1.36rem}@media (min-width:600px){h2{font-size:2.0097rem;line-height:2.52rem}h3{font-size:1.7989rem;line-height:2rem}body,ol,p,ul{font-size:1.1rem;line-height:1.6}h2,h3,ol,p,ul{margin-bottom:1.496rem}}@media (min-width:1200px){h2{font-size:2.05rem}h3{font-size:1.5rem}body,ol,p,ul{font-size:1.2rem;line-height:1.6}h2,h3,ol,p,ul{margin-bottom:1.632rem}}h1,h2,h3{font-family:var(--font-family)}a:hover{text-decoration:underline}button{border-radius:.3em;max-width:100%;background:#f2f2f2;color:#191919;cursor:pointer;padding:.75em 1.5em;text-align:center;margin:0 .75em 1.5em 0}button+label,label+*{page-break-before:always}button,label{display:inline-block}button:hover{background:#d9d9d9;color:#000}button:not([disabled]){background:#f9c412;color:#181818;background:var(--primary)}button:not([disabled]):hover{background:#ba9005;color:#000;background:var(--primary-dark)}*{border:0;box-sizing:border-box}body{font-family:var(--font-family);background:var(--bg);color:var(--fg)}header label{display:block}article,header{max-width:100%;width:42.5em;margin:0 auto}header{padding:4.5em 24px 0;text-align:center;display:flex;align-items:center;flex-direction:column}header p,ol,ul{margin-top:0}header nav .nav-title{float:left;font-size:inherit;line-height:inherit;margin:0;text-align:left}header nav label{color:#000;cursor:pointer;margin:0;font-style:normal;text-align:right}main{max-width:70rem;margin:0 auto;min-height:60vh}article{padding:1.5em;word-break:break-word}li ol,li ul{margin-bottom:0}.token.function{color:#f08d49}.token.property{color:#f8c555}.token.url{color:#67cdcc}.token.bold{font-weight:700}.token.inserted{color:green}::-webkit-scrollbar-thumb:hover{background:var(--primary)}.w-full{width:100%}body.dark{--fg: var(--bgColor);--bg: var(--fgColor);--primary: var(--primary-dark-color)}@media (prefers-color-scheme:dark){body.dark{--fg: var(--bgColor);--bg: var(--fgColor);--primary: var(--primary-dark-color)}}h1{font-size:32px;line-height:1.25;margin:.67em 0;text-align:left}header aside{font-size:16px;color:#4b4b4b}.post,footer{border-top:1px solid #ccc}.post{padding-top:35px;margin-top:35px}.menu__btn{display:inline-block;width:24px;height:24px;position:relative}.menu__btn span{opacity:0;width:1px;height:1px;overflow:hidden;display:block}.menu__btn::after,.menu__btn::before{content:"";position:absolute;top:51%;left:50%;height:2px;width:17px;background-color:#2d2d2d;border-radius:.1rem}.menu__btn::before{transform:translate(-50%,-50%);box-shadow:0 .3rem 0 #2d2d2d,0 -.3rem 0 #2d2d2d}.menu__btn::after{display:none;transform:translate(-50%,-50%) rotate(90deg)}.menu__btn.menu__btn--close{z-index:9;transform:rotate(45deg)}.menu__btn.menu__btn--close::before{box-shadow:none}.menu__btn.menu__btn--close::after{display:block}#nav,#nav .nav-title{display:flex;align-items:center}#nav{position:relative;height:68px;z-index:2}#nav .nav-title{padding:.375rem 1.5rem;width:100%;justify-content:space-between}#nav .nav-title *,.article-footer img{margin:0}.nav__links{display:none;flex-direction:column;position:fixed;z-index:3;top:0;left:0;right:0;bottom:0;padding:86px 48px 0;background-image:linear-gradient(to top,#efefef,#fff),linear-gradient(to bottom,#f9f9f9,#f9f9f9)}.nav__links--open{display:flex}.nav__links a{text-align:left;width:100%;padding:.5rem 0;transition:all .3s ease-out;font-weight:700;text-decoration:none;color:var(--fg)}.nav__links a:hover{color:var(--primary-color)}.nav-logo{width:260px;height:40px;background:url(/img/logo1.png) no-repeat center center;background-size:contain}footer{margin-top:48px;font-size:14px;padding:24px;text-align:center}.copyright{display:inline-block}footer>*{margin:.5em}.footer-logos{display:flex;align-items:center;justify-content:center}.footer-logos a:not(:first-child){margin-left:32px}.post-tags{display:flex;gap:0 16px;flex-wrap:wrap}.direct-link{display:none}.post-avatar{margin-top:27px;display:flex;align-items:center;height:36px}.post-avatar__img{width:36px;height:36px;overflow:hidden;margin:0;border-radius:50%}.post-avatar__time{font-size:13px}.post-avatar__info{margin-left:8px;color:#747474;text-align:left}.post-avatar__author{font-size:14px;font-weight:700}.article-footer{margin-top:40px;border-bottom:1px solid #ccc;padding-bottom:52px}.article-footer a{float:right;display:flex;align-items:center;color:var(--fg);font-weight:700;margin-left:4px}.article-author{margin-top:34px;display:flex;align-items:flex-start;margin-bottom:48px}.article-author__img{width:80px;height:80px;overflow:hidden;margin:0;border-radius:50%;flex-shrink:0}.article-author__info{margin-left:16px;text-align:left}.article-author__title{color:#747474;font-size:16px}.article-author__author{font-size:22px;font-weight:700;line-height:1em}.article-author__intro{color:#2f2f2f;margin-top:8px}@media (min-width:768px){h1{font-size:48px}header aside{font-size:20px}header nav a:first-of-type{margin-left:auto}header nav a:last-of-type{margin-right:1.5em}.menu__btn{display:none}#nav,footer{max-width:1168px}#nav{height:80px;margin:0 auto}.nav-logo{width:313px}.nav__links{display:flex;flex-direction:row;position:static;padding:0;background-image:none}.nav__links a{text-align:center;margin-left:56px}footer{display:flex;flex-direction:row-reverse;justify-content:space-between;align-items:center;margin-left:auto;margin-right:auto}}.notice-block{text-align:left;background:rgba(87,137,211,.2);padding:16px;margin-top:24px;border-radius:8px}</style></head><body><header><nav><div id="nav"><div class="nav-title"><a href="/" class="nav-logo" title="Homepage"></a> <label class="menu__btn" for="menu__control"><span>Menu</span></label></div><div class="nav__links"><a href="/archive/">Archive</a> <a href="/tags/">Tags</a> <a href="/about/">About</a> <a href="/en">English</a></div></div><div id="reading-progress" aria-hidden="true"></div></nav><h1 class="w-full">OpenAI Embeddings 與 Retrieval-Augmented Generation在實務中的應用與挑戰</h1><aside class="w-full"><div class="post-tags"><a href="/tags/openai/" class="post-tag">#OpenAI</a> <a href="/tags/chatgpt/" class="post-tag">#ChatGPT</a> <a href="/tags/embeddings/" class="post-tag">#Embeddings</a> <a href="/tags/rag/" class="post-tag">#RAG</a></div><div class="post-avatar"><img alt="rayH" src="/img/authors/ray_logo.jpeg" class="post-avatar__img" data-deopt="true"><div class="post-avatar__info"><div class="post-avatar__author"><a href="/posts/rayH">rayH</a></div><div class="post-avatar__time">25 Aug 2023</div></div></div><div class="notice-block" data-nosnippet="" style="display:none;">我們正在尋找一位 Security Engineer 加入我們的團隊，詳情請參考<a href="https://github.com/cymetrics/blog/issues/13" rel="noopener noreferrer" target="_blank">職缺資訊</a></div></aside><dialog id="message"></dialog></header><main><article><div id="post-page"></div><p>想了解開發 OpenAI 會遇到哪一些坑嗎？<br>想了解如何解鎖 Embeddings 和 Retrieval-Augmented Generation 讓 GPT 的模型就算沒有企業獨有的 knowhow，<br>也能產生出有意義的內容嗎？那就快點手刀點進來吧，讓您滿載而歸！</p><h2 id="%E5%89%8D%E8%A8%80"><a href="#%E5%89%8D%E8%A8%80" class="direct-link">#</a> 前言</h2><p>由 OpenAI 開發的 ChatBot 在2022年11月推出，後續對各行各業造成的影響和轟動。筆者從一個觀望的態度，開始嘗試使用一陣子，最後決定加入 ChatGPT Plus 。作為一個每日離不開 GPT 的使用者，親身體驗到其帶來的好處，不僅可以大量的加速在個人技術知識上的學習速度，工作效率，亦可以幫助在生活其他面向帶來助益，算是這幾年，經過了 3D printer, VR/AR, Web3 筆者認為最直接有幫助且進入摩擦力相對小的新技術。</p><p>目前 Cymetrics 資安產品的方向，也想利用 AI 的趨勢，為客戶提供更好的服務和價值，所以筆者有這機會來實作 AI 的產品。目前AI的服務已經發佈第一版 MVP 出去，所以有時間來寫文章，做個總結。筆者因為並非 AI 背景出生，用字遣詞如果有不精準之處，也請各位大大不吝請教和討論。</p><h2 id="%E5%AD%B8%E5%88%B0%E4%BB%80%E9%BA%BC%3F"><a href="#%E5%AD%B8%E5%88%B0%E4%BB%80%E9%BA%BC%3F" class="direct-link">#</a> 學到什麼?</h2><p>在這文章中，主要會針對下列的主題做一些通俗的介紹</p><ol><li>OpenAI embeddings 基本介紹</li><li>RAG 簡介</li><li>AI 導入實務中所遇到的困難點</li></ol><p>希望大家在讀完這篇文章後，能對某些想利用 RAG 和 embeddings 的開發者，能有更多的了解。</p><h2 id="why"><a href="#why" class="direct-link">#</a> Why</h2><p>動機是我們做一件事情最核心的部分，工程是滿足此動機的手段。所以在談論比較技術的面向前，先釐清動機算是蠻必要的事情。</p><p>以一些企業端來說，通常想要的應用不會單純只是來回的問答，更多的部分反而涉及一些複雜的需求，這些需求普遍有下列可能的問題</p><ol><li>目前 GPT 的 Model 缺乏公司獨有的產業知識</li><li>目前 OpenAI 的 GPT 的知識只到 2021 年 9 月</li></ol><p>以上的問題可能會導致使用者從 GPT 得到看似講得有道理，但其實是沒那麼正確的內容，在生成式 AI 中這稱為『 hallucination 』。所以為了解決上述的問題，我們使用了 RAG 和 embeddings 的手段來達到我們需要的業務需求。</p><h2 id="what"><a href="#what" class="direct-link">#</a> What</h2><p>那到底什麼是 embeddings 和 RAG 呢？</p><h3 id="embeddings"><a href="#embeddings" class="direct-link">#</a> Embeddings</h3><p>Embeddings 是一種將文本向量化的手段，如下圖所示。</p><p><picture><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/embedding_vector-1920w.webp 1920w, /img/posts/rayH/embeddings_rag/embedding_vector-1280w.webp 1280w, /img/posts/rayH/embeddings_rag/embedding_vector-840w.webp 840w, /img/posts/rayH/embeddings_rag/embedding_vector-320w.webp 320w" type="image/webp"><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/embedding_vector-1920w.png 1920w, /img/posts/rayH/embeddings_rag/embedding_vector-1280w.png 1280w, /img/posts/rayH/embeddings_rag/embedding_vector-840w.png 840w, /img/posts/rayH/embeddings_rag/embedding_vector-320w.png 320w" type="image/png"><img alt="" src="/img/posts/rayH/embeddings_rag/embedding_vector-1920w.png" height="698" width="2022" decoding="async" loading="lazy" style="background-size:cover;background-image:url(&#34;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 2022 698'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA0AAAAFCAYAAACeuGYRAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAh0lEQVQYlW1PywrDIBD0///MWzxJICheRDCXIMZX4pRdKDRtB4ZlWeaxAgDu+0bvneec88F/ELVWaK0hpWTRJ0hE9+u6HkZiWRY452CM4bQYI0II8N6z8DgOxH3HeZ7IOSOlBEGLtRZKKRa11lBKYVLKGIMiOY2aEAW5bduGdV1/un/Xff/0ApGN/CIneNI7AAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&#34;)"></picture></p><p>生活中，有時候會需要去釐清物體間的相似程度，譬如：蘋果跟香蕉相似嗎？一般來說這種問題可以在不到一秒就得到，但問題變成，請比較這兩段文字內容相似度？在兩段文字都沒看過的情況下，很可能會得到一個答案，『等我稍微看一下，才能分辨』，五分鐘後，才有機會得到一個答案。</p><p>但如果條件變成『 不管文字數目的多寡，都需要在一秒內告知這文本的相似程度呢 』？</p><p><picture><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/question-1920w.webp 1920w, /img/posts/rayH/embeddings_rag/question-1280w.webp 1280w, /img/posts/rayH/embeddings_rag/question-840w.webp 840w, /img/posts/rayH/embeddings_rag/question-320w.webp 320w" type="image/webp"><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/question-1920w.png 1920w, /img/posts/rayH/embeddings_rag/question-1280w.png 1280w, /img/posts/rayH/embeddings_rag/question-840w.png 840w, /img/posts/rayH/embeddings_rag/question-320w.png 320w" type="image/png"><img alt="" src="/img/posts/rayH/embeddings_rag/question-1920w.png" height="810" width="986" decoding="async" loading="lazy" style="background-size:cover;background-image:url(&#34;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 986 810'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAHCAYAAADam2dgAAAACXBIWXMAABYlAAAWJQFJUiTwAAABAklEQVQYlRXKPUsCcQDA4f9HaexTtDR1DQ5hQVBQUUGbS1MYRosYUYTmSRQOh4rS4YV3asdZVmS+nYph3mm1SRFCfoFf9MyPeOtVqOkprHIFaU5idnoK5TzEeDLidzKipCcQZsyPqUTRtAI+aYb0hoeTLS+Vcg69cIORCiOKlwfk5RCdWpPophd5WSK86uFeT9Bzu9xpcYRxEWBve42cYXKbSXK6ssDhkgc1KfP++cq1EkNkI37OdnfIXkUoqhmO170EFucp5S1abZt4OPif9qlaaewnnebzC53HBk57QN/5omX3aVTriPSRj/qDSq87wHG+cYdj+u4PbfuDVnNIMqHyB5cau4TzaQFWAAAAAElFTkSuQmCC'%3E%3C/image%3E%3C/svg%3E&#34;)"></picture></p><p>向量可以輕鬆做到相似度的比較。一個向量是否相似，看的是向量的方向和大小。所以可以根據向量的方向輕易的去判別向量的相似程度，如下圖，大部分的人可以在一秒內知道此向量Ａ和向量Ｂ並不同。</p><p><picture><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/vectorr-1920w.webp 1920w, /img/posts/rayH/embeddings_rag/vectorr-1280w.webp 1280w, /img/posts/rayH/embeddings_rag/vectorr-840w.webp 840w, /img/posts/rayH/embeddings_rag/vectorr-320w.webp 320w" type="image/webp"><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/vectorr-1920w.png 1920w, /img/posts/rayH/embeddings_rag/vectorr-1280w.png 1280w, /img/posts/rayH/embeddings_rag/vectorr-840w.png 840w, /img/posts/rayH/embeddings_rag/vectorr-320w.png 320w" type="image/png"><img alt="" src="/img/posts/rayH/embeddings_rag/vectorr-1920w.png" height="390" width="374" decoding="async" loading="lazy" style="background-size:cover;background-image:url(&#34;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 374 390'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAYAAADED76LAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAiElEQVQYlVVP7Q6DIAzk/Z9w2b/FZJMFRKAiU9pbRNHtkjZN7itVACAidRpSSiCieqtKHgSXBbO7wzuNEA5B3VKQ6YkcO6x5PJM2s8qfCGdvkHX6I1qlYi4wpGHoDRHeq4QvQXNNOaD3HdJC8C5gsMNe8Ru3OU3s8RofKFyuL1pvgyWNvM5V8AWBpvr7a4eBOAAAAABJRU5ErkJggg=='%3E%3C/image%3E%3C/svg%3E&#34;)"></picture></p><p>有了這個概念後，就不難理解為什麼需要 embeddings，如上面提到的，embeddings 本質上是一個將文本向量化的手段，所以當文本被向量後，我們可以透過向量比較非常快速去比較這文本相似程度。</p><p>但是，我們還需要思考向量的維度，如果向量只有一維，那好分辨嗎？例如下面這一維向量，看似一樣，但其實不然，雖然方向一樣，向量大小卻差了一些。</p><p><picture><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/vectorrrr-1920w.webp 1920w, /img/posts/rayH/embeddings_rag/vectorrrr-1280w.webp 1280w, /img/posts/rayH/embeddings_rag/vectorrrr-840w.webp 840w, /img/posts/rayH/embeddings_rag/vectorrrr-320w.webp 320w" type="image/webp"><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/vectorrrr-1920w.png 1920w, /img/posts/rayH/embeddings_rag/vectorrrr-1280w.png 1280w, /img/posts/rayH/embeddings_rag/vectorrrr-840w.png 840w, /img/posts/rayH/embeddings_rag/vectorrrr-320w.png 320w" type="image/png"><img alt="" src="/img/posts/rayH/embeddings_rag/vectorrrr-1920w.png" height="316" width="1152" decoding="async" loading="lazy" style="background-size:cover;background-image:url(&#34;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 1152 316'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAA8AAAAECAYAAABREWWJAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAZElEQVQImWP4TwFg+P3n1/+P397+//TtHSr+jozf///47d3/Lz8+/X/6/t7/B6+v/f/3799/BpDE5cfH/195cgIJn4Tjq09PgfGVJ6f+33x+4f+BGxv+bzo3+//v3z/+M1DibAAU+uWoydRkYQAAAABJRU5ErkJggg=='%3E%3C/image%3E%3C/svg%3E&#34;)"></picture></p><p>因此，向量維度也是判斷相似程度的一個因素，如果向量維度太低，會造成其實這向量本質上沒那麼相似，但因為維度太低(如上圖的一維陣列)，導致變得很像，誤差變高。目前來說，以 OpenAI 提供的 embeddings 出來的向量維度會是1536，而 Bert-base 是768，Bert-large 則是1024。隨著向量維度的提升，我們不難知道，向量間彼此接近或碰到的機率會越來越低，除非他們有一定程度相似程度。</p><p>總結來說：</p><ol><li>embeddings 主要是向量化文本的一種手段</li><li>向量化的比較時間成本很低</li><li>embeddings 的向量維度多寡，在一些 case 下，會影響文本相似的誤差率</li></ol><h3 id="retrieval-augmented-generation-(rag)"><a href="#retrieval-augmented-generation-(rag)" class="direct-link">#</a> <strong><strong>Retrieval Augmented Generation (RAG)</strong></strong></h3><p>RAG 的概念最早出自一篇論文(<a href="https://arxiv.org/abs/2005.11401" rel="noopener noreferrer" target="_blank">https://arxiv.org/abs/2005.11401</a>)，我們這邊不會特別去解釋作者的核心想法，有興趣的朋友可以自行去研讀論文，我們這邊關注的點反而是在如何去應用 RAG 的概念在生成式 AI 上，並具體解決了什麼樣的問題。</p><p><picture><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/rag-1920w.webp 1920w, /img/posts/rayH/embeddings_rag/rag-1280w.webp 1280w, /img/posts/rayH/embeddings_rag/rag-840w.webp 840w, /img/posts/rayH/embeddings_rag/rag-320w.webp 320w" type="image/webp"><source sizes="(max-width: 758px) 100vw, 758px" srcset="/img/posts/rayH/embeddings_rag/rag-1920w.png 1920w, /img/posts/rayH/embeddings_rag/rag-1280w.png 1280w, /img/posts/rayH/embeddings_rag/rag-840w.png 840w, /img/posts/rayH/embeddings_rag/rag-320w.png 320w" type="image/png"><img alt="" src="/img/posts/rayH/embeddings_rag/rag-1920w.png" height="1042" width="2130" decoding="async" loading="lazy" style="background-size:cover;background-image:url(&#34;data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http%3A//www.w3.org/2000/svg' xmlns%3Axlink='http%3A//www.w3.org/1999/xlink' viewBox='0 0 2130 1042'%3E%3Cfilter id='b' color-interpolation-filters='sRGB'%3E%3CfeGaussianBlur stdDeviation='.5'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type='discrete' tableValues='1 1'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter='url(%23b)' preserveAspectRatio='none' height='100%25' width='100%25' xlink%3Ahref='data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAFCAYAAACTphZWAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAp0lEQVQImW2PSwrCMABEc/+DeARxp4IKivjXWim4aFJrk1grEWxr+kQFV85q3iwejOj2+mRaE0uJUglSJSilmCxD1vsIKWPmq4D1JkAE4YF/GRxLItt8euIgv1eI9mBB6hp8XdGankmuJRdrKF0OePCeXeqITYGYLTc/28necI8aGk8vvJI/vnsFlPUTMRyOuBUF6TlDZxlGa4wxdMYh2yjmYu2H3z9e+CfNr4h1gZAAAAAASUVORK5CYII='%3E%3C/image%3E%3C/svg%3E&#34;)"></picture></p><p>(<a href="https://github.com/Azure-Samples/azure-search-openai-demo" rel="noopener noreferrer" target="_blank">https://github.com/Azure-Samples/azure-search-openai-demo</a>)</p><p>上面這張圖出自 azure-search-openai-demo 這個 repository，這個 repository 就是使用RAG精神搭配 OpenAI 的生成式 AI 解決我們在上面提到的問題，在解釋這個圖之前，我們再次釐清業務目標：『GPT 可以根據我們公司自有的產業知識，和目前在2021年9月後的資料來做回答。 』，要達到這件事情，如果我們不使用 model training 的方式，我們勢必只能在客戶的 prompt 之前加上可能的答案，然後把這內容送進 OpenAI，期待 GPT 能給我們一個精確度夠高的答案。</p><p>把剛剛這段過程對應到上面的圖的話，首先，使用者會透過一個終端設備問問題，接著我們會先走上面的路徑。我們會根據使用者的問題，試著去我們企業端的資料庫中找尋可能的答案或者去搜尋引擎找尋解法，接下來，我們才會走下面的路徑，我們會將使用者的問題和剛剛找到的可能答案一起送進 OpenAI，這樣一來，GPT 在回答使用者問題時所根據的資料，不僅是企業獨有的 knowhow 以及最新的資訊，而且可以有效的降低 GPT hallucination 的程度。</p><h1 id="how"><a href="#how" class="direct-link">#</a> How</h1><p>由上面的討論，我們現在可以理解 RAG 和 embeddings 的初步概念，接著我們要討論如何利用上面的思想去展出執行的部分細節。細節如下：</p><ol><li>將公司自己的產業知識以及相關網路最新資訊透過 OpenAI 的 embeddings API進行向量化，並將向量結果上傳到向量資料庫中(ex: Pinecone)。</li><li>將使用者的問題，透過 OpenAI 的 embeddings API得到一組向量。切記，這組向量本質上跟使用者問的問題其實是近似的。只是它用別的表現形式表現。</li><li>接著會拿著第二點得到的向量去查詢向量資料庫。</li><li>向量資料庫會根據當初設定的匹配規則，給出跟使用者問題向量『最接近』的前幾筆向量裡面的文本內容(此文本內容會是來自企業當初向量化的產業 knowhow )</li><li>而此文本內容會和使用者問題合併成一個 prompt ，送進 OpenAI GPT 裏面，並等待 GPT 的回答。</li></ol><p>以上就是 RAG 結合 embeddings 比較細節的部分，透過這個流程就可以做到讓 GPT 可以回答企業自己的 knowhow 或者是在2021/9月後才發生的事件。</p><h2 id="%E5%AF%A6%E5%8B%99%E4%B8%8A%E7%9A%84%E5%95%8F%E9%A1%8C"><a href="#%E5%AF%A6%E5%8B%99%E4%B8%8A%E7%9A%84%E5%95%8F%E9%A1%8C" class="direct-link">#</a> 實務上的問題</h2><p>雖然 RAG 和 embeddings 看似美好，但其實離真正商業化還是有不小的距離，如果要把回答的精準度大幅提高，亦需要大量時間投入，以下是實務上開發時遇到的問題。</p><h3 id="1.-embeddings%E7%9A%84%E8%B3%87%E6%96%99%E5%8F%AF%E8%83%BD%E9%9C%80%E8%A6%81%E5%85%88%E6%95%B4%E7%90%86"><a href="#1.-embeddings%E7%9A%84%E8%B3%87%E6%96%99%E5%8F%AF%E8%83%BD%E9%9C%80%E8%A6%81%E5%85%88%E6%95%B4%E7%90%86" class="direct-link">#</a> 1. embeddings的資料可能需要先整理</h3><p>送進去 embeddings 的資料格式或許會影響 embeddings 完的結果。目前的實務經驗，我們使用過 csv，也使用過 json 格式的資料，但最後 embeddings 的結果似乎沒有比通過資料清洗合併後的結果好。</p><h3 id="2.-token%E6%95%B8%E7%9B%AE%E4%BB%A5%E5%8F%8A%E6%88%90%E6%9C%AC"><a href="#2.-token%E6%95%B8%E7%9B%AE%E4%BB%A5%E5%8F%8A%E6%88%90%E6%9C%AC" class="direct-link">#</a> 2. token數目以及成本</h3><p>向量資料庫是一個額外的成本。另外，送進 OpenAI 的 token 數目可能會由歷史資訊、向量資料庫獲取回來的資訊、基礎背景資訊…等所構成，因此成本上也必須要考慮清楚是否合理。由於我們業務的特殊性，我們 prompts 的 token 數目可能是萬級起跳。</p><h3 id="3.-%E8%AA%A4%E5%B7%AE"><a href="#3.-%E8%AA%A4%E5%B7%AE" class="direct-link">#</a> 3. 誤差</h3><p>誤差是精確度最大的敵人，它可能來自幾個面向：</p><ul><li>Embeddings</li></ul><p>embeddings 有一定的誤差。誤差可能原因之一，是來自選定向量相似匹配的策略，亦可能是送進去 embeddings 的資料格式或內容。</p><ul><li>語言生成的天然特性</li></ul><p>透過 embeddings 的技巧，抓取最相關的企業 knowhow 文本，GPT 亦會一定程度給出稍微有一些偏差的結論，可能可以使用 top_p 或者 temperature 來改善，但這兩個數值太低的情況，GPT 輸出的文本會太像原本企業原本的文本，通常這不會是樂見的結果，所以如何取捨又是一個問題。</p><ul><li>prompt太長需要分割</li></ul><p>不管是 embeddings 或 prompt，都有單次能處理的 token 上限。但當你的文本太大的時候，就需要做切割，透過切割完的文本上下文通常不是是完整的，所以必須要做額外的補充處理，最後透過 GPT 產生的結果還需要分別作合併，但就算是如此，還是會造成精確度下降。</p><h3 id="4.-%E5%93%81%E8%B3%AA%E8%B7%9F%E5%9B%9E%E7%AD%94%E9%80%9F%E5%BA%A6"><a href="#4.-%E5%93%81%E8%B3%AA%E8%B7%9F%E5%9B%9E%E7%AD%94%E9%80%9F%E5%BA%A6" class="direct-link">#</a> 4. 品質跟回答速度</h3><p>目前實際測試在 prompt 中限制的規則越多，似乎會造成 response time 越長。再者，GPT 由於帶有一定的隨機性，所以常常我們並不會只有一層的問答，可能客戶一次的問題，會有三次跟 GPT 來回的交互。舉例來說，第一層可能是過濾使用者這個問題的類型，接著根據不同的類型去使用不同的模型來處理（包含參數, Model的挑選)，最後則是為品質把關或補充，這一系列為了輸出品質所做的操作都會造成 response time 拉長。</p><h3 id="5.-%E8%AA%9E%E8%A8%80%E7%9A%84%E5%95%8F%E9%A1%8C"><a href="#5.-%E8%AA%9E%E8%A8%80%E7%9A%84%E5%95%8F%E9%A1%8C" class="direct-link">#</a> 5. 語言的問題</h3><p>就算在 prompt 指定其語言，並且下一些語氣很強的關鍵字告知 GPT 回覆的語言，但輸出的結果有時候還是會出乎你的意料之外。可能的原因為當初模型在訓練時的資料是涵蓋各個語言，所以在將答案輸出時，本質上有可能會涵蓋中文英文，所以在輸出時，是有可能會是不同語言的情況發生。</p><h2 id="%E7%B5%90%E8%AB%96"><a href="#%E7%B5%90%E8%AB%96" class="direct-link">#</a> 結論</h2><p>在這篇文章中，我們對 RAG search 和 embeddings 有一些通俗的解釋，以及分享目前我們開發 AI 遇到的挑戰，希望這些東西對大家再開發 AI 上可以少踏一些陷阱，有許多地方由於篇幅關係，只能點到為止，如果反應不錯，我們會後續再針對AI的主題提出更多有趣的文章。</p><div class="article-footer"><a href="https://tech-blog.cymetrics.io/posts/rayH/embeddings_rag/" on-click="share"><img alt="Share" src="/img/icons/icon_external link hyperlink.svg" height="24" width="24">Share this post</a></div><div><p style="font-weight: bold;">Tag</p><div class="post-tags"><a href="/tags/openai/" class="post-tag">#OpenAI</a> <a href="/tags/chatgpt/" class="post-tag">#ChatGPT</a> <a href="/tags/embeddings/" class="post-tag">#Embeddings</a> <a href="/tags/rag/" class="post-tag">#RAG</a></div><p style="font-weight: bold;">Recommendation</p><ol><li><a href="/posts/alice/solidity_access_control/">以太坊智慧合約權限管理揭秘：常見的權限控制漏洞</a></li><li><a href="/posts/huli/clickjacking-intro/">不識廬山真面目：Clickjacking 點擊劫持攻擊</a></li><li><a href="/posts/huli/front-end-supply-chain-attack-cdnjs/">從 cdnjs 的漏洞來看前端的供應鏈攻擊與防禦</a></li><li><a href="/posts/jo/zerobased-secure-samesite-httponly/">零基礎資安系列（三）-網站安全三本柱（Secure & SameSite & HttpOnly）</a></li><li><a href="/posts/maxchiu/turbofan/">從編譯器優化角度初探 Javascript的V8 引擎</a></li></ol></div><div class="article-author"><img alt="rayH" src="/img/authors/ray_logo.jpeg" class="article-author__img" data-deopt="true"><div class="article-author__info"><div class="article-author__title">Author</div><div class="article-author__author"><a href="/posts/rayH">rayH</a></div><div class="article-author__intro">Software Engineer</div></div></div><p style="font-weight: bold;">Discussion(login required)</p><script async="" src="https://utteranc.es/client.js" crossorigin="anonymous" id="utterance-script" issue-term="title" label="utterance" repo="cymetrics/blog" theme="github-light"></script><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"OpenAI Embeddings 與 Retrieval-Augmented Generation在實務中的應用與挑戰","image":["https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/embedding_vector-1920w.png","https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/question-1920w.png","https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/vectorr-1920w.png","https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/vectorrrr-1920w.png","https://tech-blog.cymetrics.io/img/posts/rayH/embeddings_rag/rag-1920w.png","https://tech-blog.cymetrics.io/img/icons/icon_external link hyperlink.svg","https://tech-blog.cymetrics.io/img/authors/ray_logo.jpeg"],"author":{"@type":"Person","name":"rayH"},"publisher":{"@type":"Organization","name":"Cymetrics Tech Blog","url":"https://tech-blog.cymetrics.io","logo":{"@type":"ImageObject","url":"https://tech-blog.cymetrics.io/img/favicon/favicon-512x512.png","width":512,"height":512}},"url":"https://tech-blog.cymetrics.io/posts/rayH/embeddings_rag/","mainEntityOfPage":"https://tech-blog.cymetrics.io/posts/rayH/embeddings_rag/","datePublished":"2023-08-25","dateModified":"2025-06-04","description":"想了解開發 OpenAI 會遇到哪一些坑嗎？ 想了解如何解鎖 Embeddings 和 Retrieval-Augmented Generation 讓 GPT 的模型就算沒有企業獨有的 knowhow， 也能產生出有意義的內容嗎？那就快點手刀點進來吧，讓您滿載而歸！ # 前言..."}</script></article></main><footer><div class="footer-logos"><a href="https://www.facebook.com/cymetrics" rel="noopener noreferrer" target="_blank"><img alt="facebook" src="/img/icons/icon_social media_facebook.svg" height="30" width="30"></a><a href="https://www.linkedin.com/company/cymetrics" rel="noopener noreferrer" target="_blank"><img alt="linkedin" src="/img/icons/icon_social media_linkedln.svg" height="30" width="30"></a><a href="https://tech-blog.cymetrics.io/feed/feed.xml" rel="noreferrer noopener" target="_blank"><img alt="rss feed" src="/img/icons/rss-feed.svg" height="30" width="30"></a></div><div class="copyright">© 2025 Cymetrics Tech Blog, based on <a href="https://github.com/google/eleventy-high-performance-blog" rel="noopener noreferrer" target="_blank">eleventy-high-performance-blog</a>. <a href="https://cymetrics.io/" rel="noopener noreferrer" target="_blank">Cymetrics</a></div></footer><script>// light/dark theme switch
      // disable dark mode for now
      const menuBtn = document.querySelector('.menu__btn')
      menuBtn.addEventListener('click', function() {
        document.querySelector('body').classList.toggle('lock')
        menuBtn.classList.toggle('menu__btn--close');
        document.querySelector('.nav__links').classList.toggle('nav__links--open')
      })</script></body></html>